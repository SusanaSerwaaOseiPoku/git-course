{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c4ff327-6739-4e06-bf8a-3bc13cc1d5fc",
   "metadata": {},
   "source": [
    "# Predicting the sale price of bulldozers using machine learning\n",
    "\n",
    "In this notebook we're going to go through an example machine learning project with the goal og predicting the sale price of \n",
    "\n",
    "\n",
    "## 1. Problem definition\n",
    "How well can we predict the future price of a bulldozer given its characteristics and previous examples of how much similar bulldozers have been sold for?\n",
    "## 2. Data\n",
    "https://www.kaggle.com/competitions/bluebook-for-bulldozers/data\n",
    "\n",
    "The data is downloaded from the Keggle Bluebook for Bulldozers competition:\n",
    "\n",
    "View and download the benchmark code from Github\n",
    "\n",
    "For this competition, you are predicting the sale price of bulldozers sold at auctions.\n",
    "\n",
    "The data for this competition is split into three parts:\n",
    "\n",
    "Train.csv is the training set, which contains data through the end of 2011.\n",
    "Valid.csv is the validation set, which contains data from January 1, 2012 - April 30, 2012 You make predictions on this set throughout the majority of the competition. Your score on this set is used to create the public leaderboard.\n",
    "Test.csv is the test set, which won't be released until the last week of the competition. It contains data from May 1, 2012 - November 2012. Your score on the test set determines your final rank for the competition.\n",
    "The key fields are in train.csv are:\n",
    "\n",
    "SalesID: the uniue identifier of the sale\n",
    "MachineID: the unique identifier of a machine.  A machine can be sold multiple times\n",
    "saleprice: what the machine sold for at auction (only provided in train.csv)\n",
    "saledate: the date of the sale\n",
    "There are several fields towards the end of the file on the different options a machine can have.  The descriptions all start with \"machine configuration\" in the data dictionary.  Some product types do not have a particular option, so all the records for that option variable will be null for that product type.  Also, some sources do not provide good option and/or hours data.\n",
    "The machine_appendix.csv file contains the correct year manufactured for a given machine along with the make, model, and product class details. There is one machine id for every machine in all the competition datasets (training, evaluation, etc.).\n",
    "## 3. Evaluation\n",
    "The evaluation metric for this competition is the RMSLE (root mean squared log error) between the actual and predicted auction prices.\n",
    "\n",
    "For more on evaluation on project search:\n",
    "https://www.kaggle.com/competitions/bluebook-for-bulldozers/overview\n",
    "\n",
    "Note: the goal for most regression evaluation metrics is to minimize the error. For example the goal of this project will be to build a machine learning model which minimizes RMSLE.\n",
    "## 4. Features\n",
    "Keggle provides a data dictionary providing all of the features of a data set. You can view this data dictionary on Google Sheets:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "9cfc26c8-9905-4638-a232-904ee961c501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "8af3d527-d754-44ac-9742-09d5f497d690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "ec8a7ef6-bfa3-4f83-9096-3904d64a57fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_9296\\656879906.py:1: DtypeWarning: Columns (13,39,40,41) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"Data/bluebook-for-bulldozers/bluebook-for-bulldozers/TrainAndValid.csv\")\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 142. MiB for an array with shape (45, 412698) and data type object",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[252]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33mData/bluebook-for-bulldozers/bluebook-for-bulldozers/TrainAndValid.csv\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\bulldozer-price-prediction-project\\env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\bulldozer-price-prediction-project\\env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser.read(nrows)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\bulldozer-price-prediction-project\\env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1968\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1965\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1966\u001b[39m         new_col_dict = col_dict\n\u001b[32m-> \u001b[39m\u001b[32m1968\u001b[39m     df = DataFrame(\n\u001b[32m   1969\u001b[39m         new_col_dict,\n\u001b[32m   1970\u001b[39m         columns=columns,\n\u001b[32m   1971\u001b[39m         index=index,\n\u001b[32m   1972\u001b[39m         copy=\u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write(),\n\u001b[32m   1973\u001b[39m     )\n\u001b[32m   1975\u001b[39m     \u001b[38;5;28mself\u001b[39m._currow += new_rows\n\u001b[32m   1976\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\bulldozer-price-prediction-project\\env\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    772\u001b[39m     mgr = \u001b[38;5;28mself\u001b[39m._init_mgr(\n\u001b[32m    773\u001b[39m         data, axes={\u001b[33m\"\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m\"\u001b[39m: index, \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: columns}, dtype=dtype, copy=copy\n\u001b[32m    774\u001b[39m     )\n\u001b[32m    776\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    777\u001b[39m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m778\u001b[39m     mgr = dict_to_mgr(data, index, columns, dtype=dtype, copy=copy, typ=manager)\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma.MaskedArray):\n\u001b[32m    780\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\bulldozer-price-prediction-project\\env\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[39m, in \u001b[36mdict_to_mgr\u001b[39m\u001b[34m(data, index, columns, dtype, typ, copy)\u001b[39m\n\u001b[32m    499\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    500\u001b[39m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[32m    501\u001b[39m         arrays = [x.copy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype=dtype, typ=typ, consolidate=copy)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\bulldozer-price-prediction-project\\env\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:152\u001b[39m, in \u001b[36marrays_to_mgr\u001b[39m\u001b[34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[39m\n\u001b[32m    149\u001b[39m axes = [columns, index]\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m typ == \u001b[33m\"\u001b[39m\u001b[33mblock\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m create_block_manager_from_column_arrays(\n\u001b[32m    153\u001b[39m         arrays, axes, consolidate=consolidate, refs=refs\n\u001b[32m    154\u001b[39m     )\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m typ == \u001b[33m\"\u001b[39m\u001b[33marray\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ArrayManager(arrays, [index, columns])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\bulldozer-price-prediction-project\\env\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2139\u001b[39m, in \u001b[36mcreate_block_manager_from_column_arrays\u001b[39m\u001b[34m(arrays, axes, consolidate, refs)\u001b[39m\n\u001b[32m   2121\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_block_manager_from_column_arrays\u001b[39m(\n\u001b[32m   2122\u001b[39m     arrays: \u001b[38;5;28mlist\u001b[39m[ArrayLike],\n\u001b[32m   2123\u001b[39m     axes: \u001b[38;5;28mlist\u001b[39m[Index],\n\u001b[32m   (...)\u001b[39m\u001b[32m   2135\u001b[39m     \u001b[38;5;66;03m# These last three are sufficient to allow us to safely pass\u001b[39;00m\n\u001b[32m   2136\u001b[39m     \u001b[38;5;66;03m#  verify_integrity=False below.\u001b[39;00m\n\u001b[32m   2138\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2139\u001b[39m         blocks = _form_blocks(arrays, consolidate, refs)\n\u001b[32m   2140\u001b[39m         mgr = BlockManager(blocks, axes, verify_integrity=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   2141\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\bulldozer-price-prediction-project\\env\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2212\u001b[39m, in \u001b[36m_form_blocks\u001b[39m\u001b[34m(arrays, consolidate, refs)\u001b[39m\n\u001b[32m   2209\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(dtype.type, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m)):\n\u001b[32m   2210\u001b[39m     dtype = np.dtype(\u001b[38;5;28mobject\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2212\u001b[39m values, placement = _stack_arrays(\u001b[38;5;28mlist\u001b[39m(tup_block), dtype)\n\u001b[32m   2213\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_dtlike:\n\u001b[32m   2214\u001b[39m     values = ensure_wrapped_if_datetimelike(values)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\bulldozer-price-prediction-project\\env\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2252\u001b[39m, in \u001b[36m_stack_arrays\u001b[39m\u001b[34m(tuples, dtype)\u001b[39m\n\u001b[32m   2249\u001b[39m first = arrays[\u001b[32m0\u001b[39m]\n\u001b[32m   2250\u001b[39m shape = (\u001b[38;5;28mlen\u001b[39m(arrays),) + first.shape\n\u001b[32m-> \u001b[39m\u001b[32m2252\u001b[39m stacked = np.empty(shape, dtype=dtype)\n\u001b[32m   2253\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, arr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arrays):\n\u001b[32m   2254\u001b[39m     stacked[i] = arr\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 142. MiB for an array with shape (45, 412698) and data type object"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Data/bluebook-for-bulldozers/bluebook-for-bulldozers/TrainAndValid.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576b7627-f449-4929-9eba-2b4ee103d2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2af93c-3e54-4b35-8990-3dff5f8054df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a10f46a-ede4-40ca-a9e7-2f3b3b4980aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize\n",
    "fig, ax= plt.subplots()\n",
    "ax.scatter(df[\"saledate\"][:1000], df[\"SalePrice\"][:1000]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4225e5-bd0f-44ad-b300-03b368ef06ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.SalePrice.plot.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e70f8c-89be-46a0-b507-a24a020bc855",
   "metadata": {},
   "source": [
    "### Parsing Dates\n",
    "\n",
    "When we work with time series data we want to enrich the time and date component as much as possible. How. We can do that by telling pandas which of our columns has date in it using `parse_dates`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f93969d-0de1-4d62-838b-9a0fd74b1a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import data again but this time parse dates\n",
    "\n",
    "df=pd.read_csv(\"Data/bluebook-for-bulldozers/bluebook-for-bulldozers/TrainAndValid.csv\",\n",
    "              parse_dates=[\"saledate\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bb1d38-e480-4fb0-8e51-261b6bc291dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.saledate.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428363e7-fc10-4342-ab77-0f3efa52312c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.saledate[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eabf710-ff9a-4440-9407-d5397ed50a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704e3ecf-6f01-484a-b96c-e9b811cf412d",
   "metadata": {},
   "source": [
    "## Sort DataFrame by saledate\n",
    "\n",
    "When working with time series data it is best to sort by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876f0888-9660-4aad-979a-801c885edd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.saledate.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7716af-b8a1-4707-bfe9-bd8b6700ee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make copy of the original copy\n",
    "df_tmp=df.copy()\n",
    "df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dab0eff-c383-477f-bbf4-3e2b89ee51f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.sort_values(by=[\"saledate\"], inplace=True, ascending=True)\n",
    "df.saledate.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf62676-8426-4624-95bf-45e38a6f04f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make copy of the original copy\n",
    "df_tmp=df.copy()\n",
    "df_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebff9b6-46a2-4d8c-961a-b438276365e8",
   "metadata": {},
   "source": [
    "### Add daytime parameters for `saledate` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e78aff4-a717-4cfc-9e69-dfef43025b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp[\"saleYear\"]=df.saledate.dt.year\n",
    "df_tmp[\"saleMonth\"]=df.saledate.dt.month\n",
    "df_tmp[\"saleDay\"]=df.saledate.dt.day\n",
    "df_tmp[\"saleDayOfWeek\"]= df.saledate.dt.dayofweek\n",
    "df_tmp[\"saleDayOfYear\"]=df.saledate.dt.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f15740-a97b-4082-9559-299fb6e1656d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.drop(\"saledate\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed0ae85-c510-43e0-9479-1769005ab68f",
   "metadata": {},
   "source": [
    "# 5.Modelling\n",
    "\n",
    "We've done enough edaa. Now lets do model driven EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e483f253-d683-4df2-b107-dece8dc5cdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's build a machine learning model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model=RandomForestRegressor(n_jobs=-1,\n",
    "                           random_state=42)\n",
    "\n",
    "model.fit(df_tmp.drop(\"SalePrice\", axis=1), df_tmp[\"SalePrice\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5592aa4-c025-4b95-b7cd-ed1b940f2fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.api.types.is_string_dtype(df_tmp[\"UsageBand\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465e922d-95fd-4043-b16a-8d32958371c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Turining data to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d706bcf-ed62-4c72-bbe4-a6b78f8c3fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label,content in df_tmp.items():\n",
    "    if pd.api.types.is_string_dtype(content):\n",
    "       print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edce3c0a-e726-4258-ab7c-d6c8252d4f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This will turn all the string values to categories\n",
    "for label,content in df_tmp.items():\n",
    "    if pd.api.types.is_string_dtype(content):\n",
    "        df_tmp[label] = content.astype(\"category\").cat.as_ordered()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ef1957-0943-4a83-928a-9663fbd8b7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_tmp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aec6ba2-6fd3-49fc-b7a2-d8576fd08d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c4880d-035b-4806-812f-f484b546fb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.isnull().sum()/len(df_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d8eca2-2387-4255-bc14-67604bc077ac",
   "metadata": {},
   "source": [
    "### Save preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9989e277-dfb0-4a71-a393-42f920ec8dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Export current tmp dataframe\n",
    "df_tmp.to_csv(\"Data/bluebook-for-bulldozers/bluebook-for-bulldozers/train_tmp.csv\",\n",
    "              index=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909c809c-db01-4225-a769-a4c6253736a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import preprocessed data\n",
    "df_tmp= pd.read_csv(\"Data/bluebook-for-bulldozers/bluebook-for-bulldozers/train_tmp.csv\",\n",
    "              low_memory=False)\n",
    "\n",
    "df_tmp.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a59c90-2b7b-4e89-9dc9-9c5dd0c4fa62",
   "metadata": {},
   "source": [
    "## Fill missing numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08665c16-fc05-4f27-8a16-b3dbaa7d5654",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "for label, content in df_tmp.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96789fd2-ca6b-4981-ad70-801d16c8e93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check for which numeric columns have null values\n",
    "for label, content in df_tmp.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        if content.isnull().sum():\n",
    "            print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c66a3b4-2d72-4038-98e2-6ef11944c1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill numeric rows with median\n",
    "for label,content in df_tmp.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        if pd.isnull(content).sum:\n",
    "            df_tmp[label +\" is_missing\"] = pd.isnull(content)\n",
    "            df_tmp[label] = content.fillna(content.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863d9ebc-6674-4a37-a5f0-00581fb9917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if there are missing numeric values\n",
    "for label, content in df_tmp.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        if pd.isnull(content).sum():\n",
    "            print(label)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e00a5a-0fd1-426e-a96b-64b35e73a169",
   "metadata": {},
   "source": [
    "## Filling and turing categorical variables into numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bad9dc-8247-4f92-9e2e-7ee3b5ffe396",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check for coulumns which aren't numerical\n",
    "\n",
    "for label, content in df_tmp.items():\n",
    "    if not pd.api.types.is_numeric_dtype(content):\n",
    "        print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5d37e6-6d40-43cd-94b2-716e74fb3d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Turn categorical variables into numbers and fill missing values\n",
    "for label, content in df_tmp.items():\n",
    "    if not pd.api.types.is_numeric_dtype(content):\n",
    "        df_tmp[label +\"_is_missing\"]= pd.isnull(content)\n",
    "        ## Turn categories to numbers and add +1\n",
    "        df_tmp[label]= pd.Categorical(content).codes + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c0dcf8-8aca-4f45-81fc-e65e8e68a5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa10d90d-e155-4b1f-bf7a-81805364d887",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a742c54a-cc7e-40a2-9b1d-b81f3278fdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36841c97-cf03-4de0-9ce4-1a29ff41d155",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= RandomForestRegressor(n_jobs=-1,\n",
    "                            random_state=42)\n",
    "\n",
    "##Fit the model\n",
    "model.fit(df_tmp.drop(\"SalePrice\", axis=1), df_tmp[\"SalePrice\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982f9f95-4def-40bf-842f-bf9ae2c91c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_tmp.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cef45f1-c765-4cd5-a1d8-f99663b3e7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(df_tmp.drop(\"SalePrice\", axis=1), df_tmp[\"SalePrice\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62aaba18-6969-4d7a-af4e-2858504c8077",
   "metadata": {},
   "source": [
    "**Question:** Why doesn't the metric above hold water?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01385c0-067b-4aa1-aa43-cd316cc4d371",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split and validate the data\n",
    "df_val= df_tmp[df_tmp.saleYear==2012]\n",
    "df_train= df_tmp[df_tmp.saleYear!=2012]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f009e2a-93ef-40e7-bcde-ccf4f09d9a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train= df_train.drop(\"SalePrice\", axis=1), df_train.SalePrice\n",
    "X_valid, y_valid= df_val.drop(\"SalePrice\", axis=1), df_val.SalePrice\n",
    "\n",
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e13276-7f57-4c7a-ad3d-b884ab12f678",
   "metadata": {},
   "source": [
    "## Building an evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4a2de6-d2ac-4378-ace6-a637b4dc25ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_log_error\n",
    "import numpy as np\n",
    "\n",
    "def rmsle(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "\n",
    "def show_scores(model):\n",
    "    train_preds = model.predict(X_train)\n",
    "    val_preds = model.predict(X_valid)\n",
    "\n",
    "    scores = {\n",
    "        \"Training MAE\": mean_absolute_error(y_train, train_preds),\n",
    "        \"Validation MAE\": mean_absolute_error(y_valid, val_preds),\n",
    "        \"Training RMSLE\": rmsle(y_train, train_preds),\n",
    "        \"Validation RMSLE\": rmsle(y_valid, val_preds),\n",
    "        \"Training R^2\": r2_score(y_train, train_preds),\n",
    "        \"Validation R^2\": r2_score(y_valid, val_preds)\n",
    "    }\n",
    "\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee94b469-2ad4-4a8f-adf2-1480738533cc",
   "metadata": {},
   "source": [
    "## Testing your model on a subset(To tune hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc5fac5-67f4-4cd6-b378-e6f15b937b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7add8f5-a875-4bba-afef-a53ca8bc1050",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change max samples value\n",
    "\n",
    "model=RandomForestRegressor(n_jobs=-1,\n",
    "                           random_state=42,\n",
    "                           max_samples=10000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6222486-3ad9-4c29-b3d1-9a7137ff025c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c80ca08-bc34-40e1-bd16-bf575c48ea30",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ecacc9-b6bc-4bc7-a7eb-cef8c888e6db",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning with RandomizedSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5488595b-eb57-4ecc-a0fb-b974b55932e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "## Different RandomForest hyperparameters\n",
    "\n",
    "rf_grid= {\"n_estimators\" : np.arange(10, 100, 10),\n",
    "          \"max_depth\" : [None, 3, 5, 10],\n",
    "          \"min_samples_split\": np.arange(2, 20,2),\n",
    "          \"min_samples_leaf\" : np.arange(1, 20, 2),\n",
    "          \"max_features\" : [0.5, 1, \"sqrt\",\"auto\"],\n",
    "          \"max_samples\": [10000]\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "##Instanciate a RandomizedSearchCV model\n",
    "rs_model= RandomizedSearchCV(RandomForestRegressor(n_jobs=-1,\n",
    "                                                  random_state=42),\n",
    "                            param_distributions=rf_grid,\n",
    "                            n_iter=2,\n",
    "                            cv=5,\n",
    "                            verbose=True)\n",
    "\n",
    "\n",
    "rs_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292169fa-7ef6-41d6-83eb-43acb43129b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_model.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9446b4b0-d42f-422e-9285-4756235ef1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluate the Randomized Search Model\n",
    "\n",
    "show_scores(rs_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c23aa6-bb41-4dbe-aec4-ace980f30823",
   "metadata": {},
   "source": [
    "## Train models with best hyperparameters\n",
    "\n",
    "***Note***: These were found after 100 iterations of `RandomizedSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0b9115-2537-4d8e-9a37-b95a86530b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_model= RandomForestRegressor(n_estimators=40,\n",
    "                                  min_samples_leaf=1,\n",
    "                                  min_samples_split=14,\n",
    "                                  max_features= 0.5,\n",
    "                                  n_jobs=-1,\n",
    "                                  max_samples=None,\n",
    "                                  random_state=42)\n",
    "ideal_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a262360f-8ccd-4af2-ad13-f17c8e586432",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores(ideal_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba609f61-5ee3-48db-91e1-c46d507b4a8d",
   "metadata": {},
   "source": [
    "## Make Predictions on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "372abd98-15cf-4469-8528-2f9a711a0116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalesID</th>\n",
       "      <th>MachineID</th>\n",
       "      <th>ModelID</th>\n",
       "      <th>datasource</th>\n",
       "      <th>auctioneerID</th>\n",
       "      <th>YearMade</th>\n",
       "      <th>MachineHoursCurrentMeter</th>\n",
       "      <th>UsageBand</th>\n",
       "      <th>saledate</th>\n",
       "      <th>fiModelDesc</th>\n",
       "      <th>...</th>\n",
       "      <th>Undercarriage_Pad_Width</th>\n",
       "      <th>Stick_Length</th>\n",
       "      <th>Thumb</th>\n",
       "      <th>Pattern_Changer</th>\n",
       "      <th>Grouser_Type</th>\n",
       "      <th>Backhoe_Mounting</th>\n",
       "      <th>Blade_Type</th>\n",
       "      <th>Travel_Controls</th>\n",
       "      <th>Differential_Type</th>\n",
       "      <th>Steering_Controls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1227829</td>\n",
       "      <td>1006309</td>\n",
       "      <td>3168</td>\n",
       "      <td>121</td>\n",
       "      <td>3</td>\n",
       "      <td>1999</td>\n",
       "      <td>3688.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>2012-05-03</td>\n",
       "      <td>580G</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1227844</td>\n",
       "      <td>1022817</td>\n",
       "      <td>7271</td>\n",
       "      <td>121</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>28555.0</td>\n",
       "      <td>High</td>\n",
       "      <td>2012-05-10</td>\n",
       "      <td>936</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Conventional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1227847</td>\n",
       "      <td>1031560</td>\n",
       "      <td>22805</td>\n",
       "      <td>121</td>\n",
       "      <td>3</td>\n",
       "      <td>2004</td>\n",
       "      <td>6038.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2012-05-10</td>\n",
       "      <td>EC210BLC</td>\n",
       "      <td>...</td>\n",
       "      <td>None or Unspecified</td>\n",
       "      <td>9' 6\"</td>\n",
       "      <td>Manual</td>\n",
       "      <td>None or Unspecified</td>\n",
       "      <td>Double</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1227848</td>\n",
       "      <td>56204</td>\n",
       "      <td>1269</td>\n",
       "      <td>121</td>\n",
       "      <td>3</td>\n",
       "      <td>2006</td>\n",
       "      <td>8940.0</td>\n",
       "      <td>High</td>\n",
       "      <td>2012-05-10</td>\n",
       "      <td>330CL</td>\n",
       "      <td>...</td>\n",
       "      <td>None or Unspecified</td>\n",
       "      <td>None or Unspecified</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Triple</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1227863</td>\n",
       "      <td>1053887</td>\n",
       "      <td>22312</td>\n",
       "      <td>121</td>\n",
       "      <td>3</td>\n",
       "      <td>2005</td>\n",
       "      <td>2286.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>2012-05-10</td>\n",
       "      <td>650K</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None or Unspecified</td>\n",
       "      <td>PAT</td>\n",
       "      <td>None or Unspecified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SalesID  MachineID  ModelID  datasource  auctioneerID  YearMade  \\\n",
       "0  1227829    1006309     3168         121             3      1999   \n",
       "1  1227844    1022817     7271         121             3      1000   \n",
       "2  1227847    1031560    22805         121             3      2004   \n",
       "3  1227848      56204     1269         121             3      2006   \n",
       "4  1227863    1053887    22312         121             3      2005   \n",
       "\n",
       "   MachineHoursCurrentMeter UsageBand   saledate fiModelDesc  ...  \\\n",
       "0                    3688.0       Low 2012-05-03        580G  ...   \n",
       "1                   28555.0      High 2012-05-10         936  ...   \n",
       "2                    6038.0    Medium 2012-05-10    EC210BLC  ...   \n",
       "3                    8940.0      High 2012-05-10       330CL  ...   \n",
       "4                    2286.0       Low 2012-05-10        650K  ...   \n",
       "\n",
       "  Undercarriage_Pad_Width         Stick_Length   Thumb      Pattern_Changer  \\\n",
       "0                     NaN                  NaN     NaN                  NaN   \n",
       "1                     NaN                  NaN     NaN                  NaN   \n",
       "2     None or Unspecified                9' 6\"  Manual  None or Unspecified   \n",
       "3     None or Unspecified  None or Unspecified  Manual                  Yes   \n",
       "4                     NaN                  NaN     NaN                  NaN   \n",
       "\n",
       "  Grouser_Type     Backhoe_Mounting Blade_Type      Travel_Controls  \\\n",
       "0          NaN                  NaN        NaN                  NaN   \n",
       "1          NaN                  NaN        NaN                  NaN   \n",
       "2       Double                  NaN        NaN                  NaN   \n",
       "3       Triple                  NaN        NaN                  NaN   \n",
       "4          NaN  None or Unspecified        PAT  None or Unspecified   \n",
       "\n",
       "  Differential_Type Steering_Controls  \n",
       "0               NaN               NaN  \n",
       "1          Standard      Conventional  \n",
       "2               NaN               NaN  \n",
       "3               NaN               NaN  \n",
       "4               NaN               NaN  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Import the test data\n",
    "df_test= pd.read_csv(\"Data/bluebook-for-bulldozers/bluebook-for-bulldozers/Test.csv\",\n",
    "                    low_memory=False,\n",
    "                    parse_dates=[\"saledate\"])\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "f1509231-8b3f-4ce8-9967-0d4f96945b24",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- saledate\nFeature names seen at fit time, yet now missing:\n- Backhoe_Mounting_is_missing\n- Blade_Extension_is_missing\n- Blade_Type_is_missing\n- Blade_Width_is_missing\n- Coupler_System_is_missing\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[258]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m## Make predictions on the test dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m test_preds= ideal_model.predict(df_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\bulldozer-price-prediction-project\\env\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:1066\u001b[39m, in \u001b[36mForestRegressor.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m   1064\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m   1065\u001b[39m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1066\u001b[39m X = \u001b[38;5;28mself\u001b[39m._validate_X_predict(X)\n\u001b[32m   1068\u001b[39m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[32m   1069\u001b[39m n_jobs, _, _ = _partition_estimators(\u001b[38;5;28mself\u001b[39m.n_estimators, \u001b[38;5;28mself\u001b[39m.n_jobs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\bulldozer-price-prediction-project\\env\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:638\u001b[39m, in \u001b[36mBaseForest._validate_X_predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    635\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    636\u001b[39m     ensure_all_finite = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m638\u001b[39m X = validate_data(\n\u001b[32m    639\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    640\u001b[39m     X,\n\u001b[32m    641\u001b[39m     dtype=DTYPE,\n\u001b[32m    642\u001b[39m     accept_sparse=\u001b[33m\"\u001b[39m\u001b[33mcsr\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    643\u001b[39m     reset=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    644\u001b[39m     ensure_all_finite=ensure_all_finite,\n\u001b[32m    645\u001b[39m )\n\u001b[32m    646\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X.indices.dtype != np.intc \u001b[38;5;129;01mor\u001b[39;00m X.indptr.dtype != np.intc):\n\u001b[32m    647\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\bulldozer-price-prediction-project\\env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2919\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2835\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalidate_data\u001b[39m(\n\u001b[32m   2836\u001b[39m     _estimator,\n\u001b[32m   2837\u001b[39m     /,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2843\u001b[39m     **check_params,\n\u001b[32m   2844\u001b[39m ):\n\u001b[32m   2845\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Validate input data and set or check feature names and counts of the input.\u001b[39;00m\n\u001b[32m   2846\u001b[39m \n\u001b[32m   2847\u001b[39m \u001b[33;03m    This helper function should be used in an estimator that requires input\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2917\u001b[39m \u001b[33;03m        validated.\u001b[39;00m\n\u001b[32m   2918\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2919\u001b[39m     _check_feature_names(_estimator, X, reset=reset)\n\u001b[32m   2920\u001b[39m     tags = get_tags(_estimator)\n\u001b[32m   2921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tags.target_tags.required:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\bulldozer-price-prediction-project\\env\\Lib\\site-packages\\sklearn\\utils\\validation.py:2777\u001b[39m, in \u001b[36m_check_feature_names\u001b[39m\u001b[34m(estimator, X, reset)\u001b[39m\n\u001b[32m   2774\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[32m   2775\u001b[39m     message += \u001b[33m\"\u001b[39m\u001b[33mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2777\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[31mValueError\u001b[39m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- saledate\nFeature names seen at fit time, yet now missing:\n- Backhoe_Mounting_is_missing\n- Blade_Extension_is_missing\n- Blade_Type_is_missing\n- Blade_Width_is_missing\n- Coupler_System_is_missing\n- ...\n"
     ]
    }
   ],
   "source": [
    "## Make predictions on the test dataset\n",
    "\n",
    "test_preds= ideal_model.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711b5328-e4e8-4809-b559-899d06a1eed9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529d91df-c8fd-48f5-91b8-534171e9d50b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38567a0c-ab97-4b4d-9a7e-2257d2a994ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea81888-65c0-4cd0-9223-2bc9b2d546f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7990b9a2-ce10-4a0f-b64e-b0b111fc1f58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3785373-24b8-499f-86e3-a9a2d3e72fac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c42b27-a03f-4baa-91d7-87090c224c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1d1213-c9c2-45ad-a157-bfd92217a5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abc25a9-bb2d-44b9-ad65-391afb37e6f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
